# ✍️ Отчёт по проекту: Классификация авторов по стилю текста (BERT)

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red?logo=pytorch)
![Model](https://img.shields.io/badge/Model-RuBERT-green?logo=transformers)
![Accuracy](https://img.shields.io/badge/Val_Accuracy-78%25-brightgreen)

---

## 🧠 1. Описание задачи и обоснование подхода

Цель — построить модель, которая сможет по небольшому отрывку текста определить, кто является его автором. Используются тексты 6 авторов: **Bradbury, Bulgakov, Fry, Genri, Simak, Strugatskie**.

Задача относится к области анализа текстов (NLP) и требует распознавания стилистических различий между авторами.

Для решения применена предобученная модель трансформера **RuBERT** (`DeepPavlov/rubert-base-cased`), т.к. она учитывает контекст и языковые зависимости на уровне предложений и фраз.

---

## ⚙️ 2. Обоснование выбора методов и инструментов

### 📄 Предобработка текста
- Очистка текста от лишних символов (оставлены только буквы, пробелы, точки)
- Перевод в нижний регистр
- Разбиение на фрагменты (50–300 символов)
- Ограничение выборки: до 1000 фрагментов на автора

### 🧰 Инструменты
- `HuggingFace Transformers` — загрузка модели и токенизатора
- `PyTorch` — реализация классификатора
- `scikit-learn` — метки, метрики, визуализация
- `tqdm`, `matplotlib`, `seaborn` — логирование и графики

### 🏗 Архитектура модели
- `BertModel` без классификационной головы
- `Dropout(p=0.3)`
- `Linear(768 → 6)` — выходной слой

### ⚙️ Гиперпараметры
- Batch size: `32`
- Learning rate: `2e-5`
- Epochs: `5`
- Max length: `256`

---

## 🚀 3. Обучение модели

Обучение модели происходило на сбалансированном датасете:
- **Train**: 4800 текстов (по 800 на каждого автора)
- **Validation**: 1200 текстов (по 200 на каждого)

| Epoch | Train Acc | Val Acc |
|-------|-----------|---------|
| 1     | 0.64      | 0.72    |
| 2     | 0.89      | 0.76    |
| 3     | 0.96      | 0.77 ✅ |
| 4     | 0.98      | 0.76    |
| 5     | 0.99      | 0.75    |

- 📈 Лучшее качество — на 3-й эпохе
- 📉 Признаки переобучения с 4-й эпохи

---

## 📊 4. Интерпретация результатов

**Macro F1:** `0.78`  
**Accuracy:** `0.78`

### 🔥 Лучшие классы (по F1):
- Bulgakov — `0.86`
- Genri — `0.80`
- Fry — `0.78`

📉 Ошибки в основном между похожими стилями (например, Fry и Strugatskie).

**Confusion Matrix** и `classification_report` показывают сбалансированную производительность по классам.

---

## 💡 Рекомендации по улучшению

- 🕐 Ввести `early stopping` по метрике валидации
- 📊 Попробовать `weighted` или `focal` loss
- 📚 Добавить больше фрагментов в тренировку
- ❄️ Заморозить часть слоёв BERT для ускорения обучения

---

## ✅ Итог

Модель на основе **RuBERT** успешно решает задачу классификации по авторству на русском языке. Качество на валидации составляет **~78%**, и метрики по классам сбалансированы.

> Подход показал высокую эффективность и уверенно превосходит более простые архитектуры (например, LSTM).

📁 Финальный файл: `submission_BERT.csv`
📓 Ноутбук: `hw1_BERT.ipynb`
📄 Описание: `hw1_BERT.md`