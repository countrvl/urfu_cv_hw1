# 🧠 Отчёт по проекту: Классификация авторов по стилю текста (LSTM)

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red?logo=pytorch)
![Model](https://img.shields.io/badge/Model-LSTM-orange?logo=pytorch)
![Accuracy](https://img.shields.io/badge/Val_Accuracy-37%25-lightgrey)

---

## 🎯 1. Цель и описание задачи

Задача — классифицировать текстовые фрагменты по авторству. Выборка содержит тексты 6 авторов: **Bradbury, Bulgakov, Fry, Genri, Simak, Strugatskie**.

Цель — научить модель различать стили разных писателей, анализируя отрывки длиной 50–300 символов.

---

## ⚙️ 2. Подход и архитектура

### 🔧 Инструменты:
- `PyTorch` — построение и обучение модели
- `sklearn` — метки, отчёты и метрики
- `tqdm`, `matplotlib`, `seaborn` — визуализация

### 🧹 Предобработка:
- Очистка текста от символов, кроме букв, пробелов и точек
- Приведение к нижнему регистру
- Разбиение по точкам
- Ограничение длины и количества фрагментов на автора (до 500)

### 🧠 Архитектура LSTM-модели:
- `Embedding(vocab_size, embedding_dim)`
- `BiLSTM(hidden_dim)`
- `Dropout(p=0.3)`
- `Linear(hidden_dim * 2 → 6)` — выходной слой

### ⚙️ Гиперпараметры:
- Embedding dim: `200`
- Hidden dim: `128`
- Bidirectional: `True`
- Batch size: `128`
- Max len: `200`
- Epochs: `50`

---

## 🚀 3. Обучение и результаты

| Epoch | Train Acc | Val Acc |
|-------|-----------|---------|
| 1     | 0.20      | 0.26    |
| 5     | 0.76      | 0.49    |
| 10    | 0.98      | 0.56    |
| 20    | 1.00      | 0.57    |
| 50    | 1.00      | 0.49    |

- Наблюдается резкое переобучение после 10-й эпохи
- Train accuracy достигла 100%, но валидационная метрика перестала расти

---

## 📊 4. Анализ метрик

**Accuracy:** `0.37`  
**Macro F1:** `0.35`

### Примеры F1-метрик:
- Fry — `0.58`
- Strugatskie — `0.42`
- Bulgakov — `0.39`
- Genri — `0.13` 👎

**Confusion matrix** показывает, что модель часто путает авторов между собой.

---

## 🧪 5. Выводы и ограничения

Модель обучается, но **не обобщает** на валидационной выборке. Даже при сбалансированной обучающей выборке наблюдается **резкое переобучение**.

Возможные причины:
- Недостаточная архитектура (простая LSTM)
- Слишком маленький объём данных
- Переобучение на редких словах или фразах

---

## 💡 Рекомендации по улучшению

- Ввести `early stopping`
- Использовать регуляризацию (`weight decay`)
- Добавить слои и увеличить размер LSTM
- Применить предварительное обучение (`word2vec`, `fastText`)
- Перейти на трансформеры (как BERT)

---

## 🧾 Финал

Простая модель на основе LSTM показала **ограниченные результаты**:
- Хорошо учится, но плохо обобщает
- Не подходит как финальное решение

> Модель полезна как стартовая база и учебный пример, но требует глубокой переработки или замены на современные архитектуры.

📁 Финальный файл: `submission_LSTM.csv`  
📓 Ноутбук: `hw1_LSTM.ipynb`  
📄 Описание: `hw1_LSTM.md`
