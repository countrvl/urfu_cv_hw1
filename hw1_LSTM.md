# Отчёт по проекту: Классификация авторов по стилю текста

## 1. Описание задачи и обоснование подхода

Задача проекта — классифицировать текст по авторству. Для этого используются тексты 6 авторов (Bradbury, Bulgakov, Fry, Genri, Simak, Strugatskie), разбитые на короткие фрагменты. 

Цель — построить модель, которая сможет по небольшому отрывку текста определить, кто является его автором. Данная задача относится к области анализа текстов (NLP) и требует понимания стилистических различий между авторами.

Для решения выбрана модель на основе **двунаправленной LSTM**, так как она позволяет учитывать как контекст слева, так и справа от текущего слова, что важно для литературных стилей. 

На первом этапе была реализована модель с обычной (однонаправленной) LSTM, но она показала низкую точность (Val Accuracy ≈ 16–17%), практически соответствующую случайному угадыванию. После добавления `bidirectional=True` точность значительно улучшилась. Наилучший результат на валидации составил **~51%**, а в отдельных запусках достигал **~57%**.

---

## 2. Обоснование выбора методов, инструментов и архитектуры моделей

### Предобработка текста
- Перевод в нижний регистр
- Удаление всех символов, кроме букв, пробелов и точек
- Разделение на фрагменты по предложениям длиной до 300 символов
- Исключение коротких фрагментов (менее 50 символов)
- Балансировка выборки: одинаковое количество фрагментов на каждого автора

### Выбор инструментов
- **PyTorch** — удобен для построения кастомных моделей и прозрачного контроля за обучением
- **sklearn** — для разметки классов и расчёта метрик
- **seaborn / matplotlib** — для визуализации результатов

### Архитектура модели
- Embedding слой (размерность 200)
- Bidirectional LSTM (hidden_dim = 128)
- Dropout = 0.3
- Полносвязный слой `Linear(hidden_dim * 2 → num_classes)`
- Функция потерь — `CrossEntropyLoss`
- Оптимизатор — `Adam`

### Гиперпараметры
- Batch size: 64
- Learning rate: 0.001
- Эпох: 50
- Максимальная длина текста (max_len): 200 слов

---

## 3. Разработка модели и обучение

Реализована модель `LSTMClassifier`, включающая embedding, двунаправленный LSTM и полносвязный слой. Преобразование текста в токены происходит через словарь (`vocab`), где `<PAD>` и `<UNK>` зарезервированы.

Модель обучалась на сбалансированной выборке. Результаты обучения по эпохам логируются. Также реализована визуализация графиков `loss` и `accuracy` по эпохам.

Результаты:
- Train accuracy достигло 100% к 20-й эпохе и сохранялось до конца обучения
- Validation accuracy достигало максимума **~51.1%**, однако в среднем держалось в пределах **~48–50%** в течение последних 40 эпох

---

## 4. Интерпретация результатов в отчёте

Построены `confusion_matrix` и `classification_report`.

### Ключевые наблюдения:
- **Simak** (F1=0.45) и **Bradbury** (F1=0.56) показали наивысшие значения recall
- **Bulgakov** имеет очень низкий recall (0.07) — модель почти не распознаёт его
- **Fry** и **Strugatskie** часто путаются между собой
- **Валидационная точность стабилизировалась около 50%, при этом модель демонстрирует уверенное переобучение (Train Acc = 100%)**

### Выводы:
- Модель склонна к переобучению после ~15 эпох
- Присутствует сильная несбалансированность по качеству между классами
- Классы с наиболее выраженным стилем (Simak, Bradbury) распознаются лучше

### Рекомендации по улучшению:
- Применить `class weights` в `CrossEntropyLoss` для борьбы с перекосом
- Увеличить объём данных для авторов с низким recall
- Использовать предобученные эмбеддинги (например, FastText)
- Попробовать архитектуры на основе BERT
- Добавить `early stopping` по валидационной метрике

---

## Итог
Задача классификации авторов успешно решена с помощью LSTM-модели. Получено рабочее решение с Val Accuracy ~50% и разумными метриками F1-score для некоторых классов. Проведён полный цикл: от предобработки текста до анализа ошибок и обсуждения направлений для улучшения.

